{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Based on the class defined above, we create training and validation datasets.\n",
    "from transformers import DetrFeatureExtractor\n",
    "from lib.DETR import CocoDetection\n",
    "feature_extractor = DetrFeatureExtractor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "feature_extractor.max_size = 256\n",
    "feature_extractor.size = 128\n",
    "\n",
    "DATA_BASE = 'data/custom/'\n",
    "train_dataset = CocoDetection(img_folder=f'{DATA_BASE}/train', feature_extractor=feature_extractor)\n",
    "val_dataset = CocoDetection(img_folder=f'{DATA_BASE}/val', feature_extractor=feature_extractor, train=False)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "  pixel_values = [item[0] for item in batch]\n",
    "  encoding = feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "  labels = [item[1] for item in batch]\n",
    "  batch = {}\n",
    "  batch['pixel_values'] = encoding['pixel_values']\n",
    "  batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['labels'] = labels\n",
    "  return batch\n",
    "\n",
    "\n",
    "def to_jax(batch):\n",
    "    batch['pixel_values'] = jnp.array(batch['pixel_values'].numpy().transpose(0,2,3,1))\n",
    "    batch['pixel_mask'] = jnp.array(batch['pixel_mask'])\n",
    "    batch['labels'] = [{k: jnp.array(v) for k,v in n.items()} for n in batch['labels']]\n",
    "    return batch\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=1, shuffle=False, num_workers = 1)\n",
    "val_dataloader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=1, shuffle=False, num_workers = 1)\n",
    "cats = val_dataset.coco.cats\n",
    "# Use this for the # classes\n",
    "id2label = {k: v['name'] for k,v in cats.items()}\n",
    "\n",
    "t_it = iter(train_dataloader)\n",
    "batch = next(t_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "           ...,\n",
       "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
       "           [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],\n",
       " \n",
       "          [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "           ...,\n",
       "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],\n",
       "           [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],\n",
       " \n",
       "          [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "           ...,\n",
       "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],\n",
       "           [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]]]),\n",
       " 'pixel_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]]),\n",
       " 'labels': [{'boxes': tensor([[0.5000, 0.4518, 0.8625, 0.1933],\n",
       "           [0.1441, 0.5269, 0.1507, 0.0539],\n",
       "           [0.1441, 0.5808, 0.1507, 0.0539]]),\n",
       "   'class_labels': tensor([0, 1, 1]),\n",
       "   'image_id': tensor([0]),\n",
       "   'area': tensor([4843.9297,  235.8687,  235.8687]),\n",
       "   'iscrowd': tensor([0, 0, 0]),\n",
       "   'orig_size': tensor([540, 960]),\n",
       "   'size': tensor([128, 227]),\n",
       "   'rotation': tensor([[1., 0.],\n",
       "           [1., 0.],\n",
       "           [1., 0.]]),\n",
       "   'fill': tensor([[1., 1., 1.],\n",
       "           [1., 1., 1.],\n",
       "           [1., 1., 1.]])}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
